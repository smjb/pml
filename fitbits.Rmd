---
title: "Exercise quality prediction based on wearables devices data"
author: "smjb"
date: "September 22, 2015"
output: html_document
---

```{r cache=T, echo=FALSE}
rm(list=ls())
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
verifyUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
setwd("D:/coursera/sandbox/pml")

```
```{r lib,echo=T, warning=F, error=F,message=F}
library(caret)
library(dplyr)
library(ggplot2)
library(randomForest)
library(rpart)
library(rpart.plot)

```

#Introduction

Devices such as Jawbone Up, Nike FuelBand, and Fitbit is used to collect a large amount of data about personal activity. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

Researchers from [Department of Informatics, Pontifical Catholic University of Rio de Janeiro](www.puc-rio.br/english/) have conducted an experiment where they invite 6 participants to perform barbell lifts correctly and incorrectly in 5 different ways. They collect data from accelerometers on the belt, forearm, arm, and dumbell of these participants. More information is available from the [website here](http://groupware.les.inf.puc-rio.br/har) (see the section on the Weight Lifting Exercise Dataset). 

The data are downloaded in two parts : the [training](`r paste(trainUrl)`) set and the [test](`r paste(verifyUrl)`) set.


#Objective and Methodology

The goal of this report is to show the prediction of the manner in which they did the exercise. This is the "classe" variable in the training set. 

The data is first cleaned and only the relevant measurement columns without missing values will be selected to be used in the prediction.

The training source dataset is first split into two with 65:35 ratio. 65% is for model training, while the 35% is for model validation. We also use 3 different prediction methods (Trees, Random Forest, and Boosting ) to compare the accuracy using the model validation dataset. The source test dataset is finally used to validate the prediction model made.

Note that the memory requirement is extremely high if we use all the columns in the *train* function. We conciously only used  columns that are fully numeric without missing values.

# original instruction
_You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases._

#Data Cleansing
##Loading the source dataset

```{r init,cache=T, echo=T, warning=F, error=F,message=F}

## Load data, download if not yet available.

fbigdata <- "pml-training.csv"
fverify <- "pml-testing.csv"

db_dl<-F
if(!file.exists(fbigdata)) {
    download.file(trainUrl, fbigdata, method="auto")
    db_dl<-T
}

ver_dl<-F
if(!file.exists(fverify)) {
    download.file(verifyUrl, fverify, method="auto")
    ver_dl<-T
}

dDB <- read.csv(fbigdata) 
DB_dim <- dim(dDB)
dVerify <- read.csv(fverify)
verify_dim <- dim(dVerify)
```

The training data was `r paste0(ifelse(db_dl, "downloaded from source server and stored locally before being read.", "read from local cache."))`. Training file dimension is `r DB_dim[1]`x`r DB_dim[2]`.

There are only `r sum(complete.cases(dDB))` complete cases found in the training data.

The validation data was `r paste0(ifelse(ver_dl, "downloaded from source server and stored locally before being read.", "read from local cache."))`. Training file dimension is `r verify_dim[1]`x`r verify_dim[2]`.

##Cleaning and selecting the measurement

We extract the names of each column and identify the columns that are actually measurements. We also identify columns that have missing values and those that don't. Finally we only use measurement columns that have no missing values and where the values are numeric.

```{r cleandata,cache=T, echo=T, warning=F, error=F,message=F}
cnames <- data.frame(coln=colnames(dDB))
cnames <- mutate(cnames, idx = as.numeric(rownames(cnames)), measurement = !grepl("^X|timestamp|window|user|classe", coln))
mcol <- filter(cnames, measurement==TRUE) %>% select(idx)

v<-data.frame() # temporary variable
for (i  in 1:DB_dim[2]) {
    r <- data.frame(idx=i, coln=names(dDB)[i], isna = length(which(is.na(dDB[,i]))))
    v<-rbind(v,r)
}

v <- mutate(v, extra_info = grepl("^X|timestamp|window", coln),measurement = !grepl("^X|timestamp|window|user|classe", coln))

#Create subset data where only measurement columns without missing values are selected
complete_measurement_cols <- filter(v, extra_info==FALSE, isna==0)
rm("v") # remove temporary
rm("r") # remove temporary

dDB_subset <- select(dDB, complete_measurement_cols$idx)

#attempt to use numerical fields only, due to memory limitation
classetemp <- dDB_subset$classe

#Create smaller subset data where only numerical measurement columns without missing values are selected
dDB_num_subset_idx <- sapply(dDB_subset, is.numeric)

dDB_num_subset <- cbind(classe=classetemp, dDB_subset[,dDB_num_subset_idx])
dim_dDB_num_subset <- dim(dDB_num_subset)

## pseudo cleaning complete ... 
```
After the cleaning and subsetting process, the cleaned training data dimension is `r dim_dDB_num_subset[1]` rows and `r dim_dDB_num_subset[2]` columns.

##Predicting

```{r predict,cache=T, echo=T, warning=F, error=F,message=F}
set.seed(13927) 
dDB_num_subset_part <- createDataPartition(dDB_num_subset$classe, p=0.65, list=F)
dDB_num_subset_train <- dDB_num_subset[dDB_num_subset_part, ]
dDB_num_subset_test <- dDB_num_subset[-dDB_num_subset_part, ]

ctrlRf <- trainControl(method="cv", 5)
```
```{r predict_rpart,cache=T, echo=T, warning=F, error=F,message=F}
dDB_cc_model_rpart <- train(classe ~ ., data=dDB_num_subset_train, method="rpart", trControl=ctrlRf)
dDB_cc_model_rpart
```
```{r predict_rf,cache=T, echo=T, warning=F, error=F,message=F}
dDB_cc_model_rf <- train(classe ~ ., data=dDB_num_subset_train, method="rf", trControl=ctrlRf, ntree=250)
dDB_cc_model_rf
```
```{r predict_gbm,cache=T, echo=T, warning=F, error=F,message=F}
dDB_cc_model_gbm <- train(classe ~ ., data=dDB_num_subset_train, method="gbm", trControl=ctrlRf)
dDB_cc_model_gbm

```

```{r acc_rpart,cache=T, echo=T, warning=F, error=F,message=F}
modelpred_rpart <- predict(dDB_cc_model_rpart, dDB_num_subset_test)
modelpred_rpart
confusionMatrix(dDB_num_subset_test$classe, modelpred_rpart)
accuracy <- postResample(modelpred_rpart, dDB_num_subset_test$classe)
accuracy
as.numeric(confusionMatrix(dDB_num_subset_test$classe, modelpred_rpart)$overall[1])
```